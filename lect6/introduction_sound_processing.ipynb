{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eee1385",
   "metadata": {},
   "source": [
    "ideas taken from: https://www.kaggle.com/code/salimhammadi07/esc-50-environmental-sound-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/sounds/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ed8679",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls data/sounds/background/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1243b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio('data/sounds/background/background_00.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c7dcf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Audio('data/sounds/chainsaw/chainsaw_00.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d517e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8773e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load('data/sounds/chainsaw/chainsaw_00.wav')\n",
    "print('y:', y, '\\n')\n",
    "print('y shape:', np.shape(y), '\\n')\n",
    "print('Sample Rate (KHz):', sr, '\\n')\n",
    "\n",
    "# The duration is equal to the number of frames divided by the framerate\n",
    "print('Duration of the audio file:', np.shape(y)[0]/sr, 'second')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f845ff2d",
   "metadata": {},
   "source": [
    "Load all sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19237e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "all_waves = {}\n",
    "base_path = \"data/sounds\"\n",
    "for category in ['background', 'chainsaw', 'engine', 'storm']:\n",
    "    all_waves[category] = []\n",
    "    for audio_file in os.listdir(os.path.join(base_path, category)):\n",
    "        file_name = os.path.join(base_path, category, audio_file)\n",
    "        y, sr = librosa.load(file_name)\n",
    "        all_waves[category].append((y, sr, file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde41013",
   "metadata": {},
   "source": [
    "# Sound Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57651a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr, file_name = all_waves['background'][0]\n",
    "Audio(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1ada9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "librosa.display.waveshow(y[10000:11000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a85f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_in_plots(fn, cant_per_row=3, xlabel=None, ylabel=None):\n",
    "    plt.figure(figsize=(30,30))\n",
    "    idx = 1\n",
    "    for cat_name, items in all_waves.items():\n",
    "        for y, sr, _ in items[:cant_per_row]:\n",
    "            plt.subplot(4,cant_per_row,idx)\n",
    "            idx += 1\n",
    "            fn(y, sr)\n",
    "            if xlabel:\n",
    "                plt.xlabel(xlabel)\n",
    "            if ylabel:\n",
    "                plt.ylabel(ylabel)\n",
    "            plt.title(cat_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c4c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _waveshow(y, sr):\n",
    "    librosa.display.waveshow(y)\n",
    "    \n",
    "show_in_plots(_waveshow, xlabel=\"Time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1f3d31",
   "metadata": {},
   "source": [
    "# Visualize Audio : Fourier Transform\n",
    "\n",
    "The Fourier transform is a mathematical technique used to decompose a signal into its constituent frequency components. It is widely used in audio signal processing to analyze, filter and manipulate sound signals.\n",
    "\n",
    "The Fourier transform of a time-domain signal, such as an audio signal, produces a frequency-domain representation of the signal. This representation shows the relative amplitudes of the different frequency components that make up the signal. This information is useful for understanding the characteristics of the sound, such as its pitch and timbre, and for filtering or modifying specific frequency ranges.\n",
    "\n",
    "There are different types of Fourier transforms, the most common is the discrete Fourier transform (DFT), which is used to convert a discrete-time signal into a discrete-frequency representation. The DFT requires a large amount of computation, so in practice, the fast Fourier transform (FFT) algorithm is often used to efficiently calculate the DFT.\n",
    "\n",
    "The short-time Fourier transform (STFT) is a variation of the DFT that is used to analyze audio signals. It breaks the audio signal into short segments and applies the DFT to each segment, providing a time-frequency representation of the signal. This is useful for analyzing the frequency content of a sound over time, and for tasks such as pitch detection and audio compression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6632a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr, file_name = all_waves['chainsaw'][0]\n",
    "Audio(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b05fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default FFT window size\n",
    "n_fft = 2048 # FFT window size\n",
    "hop_length = 512 # number audio of frames between STFT columns \n",
    "\n",
    "X = np.abs(librosa.stft(y, n_fft = n_fft, hop_length = hop_length))\n",
    "plt.plot(X)\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df243b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fftshow(y, sr):\n",
    "    X = np.abs(librosa.stft(y, n_fft = n_fft, hop_length = hop_length))\n",
    "    plt.plot(X)\n",
    "    \n",
    "show_in_plots(_fftshow, xlabel=\"Frequency\", ylabel=\"Amplitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8949ce",
   "metadata": {},
   "source": [
    "# Spectrogram\n",
    "\n",
    "A spectrogram is a time-frequency representation of a signal, such as an audio signal. It is a graphical representation of the frequency content of a signal over time, and is often used to visualize and analyze audio signals.\n",
    "\n",
    "A spectrogram is typically represented as a 2D image, with the x-axis representing time, the y-axis representing frequency, and the intensity of the color or grayscale representing the amplitude of the frequency component at that point in time.\n",
    "\n",
    "The spectrogram is calculated by applying the Short-Time Fourier Transform (STFT) to the audio signal, which breaks the audio into short segments and applies the Fourier transform to each segment. This produces a set of complex numbers representing the frequency content of the audio for each segment, which are then plotted in the spectrogram.\n",
    "\n",
    "A spectrogram can be useful for visualizing the frequency content of a sound over time, and for identifying patterns in the audio signal, such as pitch, timbre, and transient events. It can also be used to analyze the characteristics of different sounds, such as the spectral envelope or the harmonic structure, and to segment an audio file into different sound events.\n",
    "\n",
    "A spectrogram can be used in many audio-related tasks, such as speech recognition, audio source separation, and audio event detection, and it is an essential tool in the field of audio signal processing.\n",
    "\n",
    "We can display a spectrogram using. librosa.display.specshow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c31991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _expectrogramshow(y, sr):\n",
    "    X = librosa.stft(y)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "    plt.colorbar()\n",
    "    \n",
    "show_in_plots(_expectrogramshow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359ae0e0",
   "metadata": {},
   "source": [
    "# Mel Spectrogram\n",
    "## The Mel Scale\n",
    "\n",
    "Studies have shown that humans do not perceive frequencies on a linear scale. We are better at detecting differences in lower frequencies than higher frequencies. For example, we can easily tell the difference between 500 and 1000 Hz, but we will hardly be able to tell a difference between 10,000 and 10,500 Hz, even though the distance between the two pairs are the same.\n",
    "\n",
    "In 1937, Stevens, Volkmann, and Newmann proposed a unit of pitch such that equal distances in pitch sounded equally distant to the listener. This is called the mel scale. We perform a mathematical operation on frequencies to convert them to the mel scale.\n",
    "\n",
    "## The Mel Spectrogram\n",
    "\n",
    "- A mel spectrogram is a spectrogram where the frequencies are converted to the mel scale.\n",
    "\n",
    "- A mel spectrogram logarithmically renders frequencies above a certain threshold (the corner frequency). For example, in the linearly scaled spectrogram, the vertical space between 1,000 and 2,000Hz is half of the vertical space between 2,000Hz and 4,000Hz. In the mel spectrogram, the space between those ranges is approximately the same. This scaling is analogous to human hearing, where we find it easier to distinguish between similar low frequency sounds than similar high frequency sounds.\n",
    "\n",
    "- A mel spectrogram computes its output by multiplying frequency-domain values by a filter bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb5b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr, file_name = all_waves['background'][1]\n",
    "Audio(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fbe130",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = librosa.effects.trim(y)\n",
    "XS = librosa.feature.melspectrogram(y=X, sr=sr)\n",
    "Xdb = librosa.amplitude_to_db(XS, ref=np.max)\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='mel')\n",
    "plt.colorbar() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a9831",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr, file_name = all_waves['storm'][2]\n",
    "Audio(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda27488",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = librosa.effects.trim(y)\n",
    "XS = librosa.feature.melspectrogram(y=X, sr=sr)\n",
    "Xdb = librosa.amplitude_to_db(XS, ref=np.max)\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='mel')\n",
    "plt.colorbar() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd1e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _melexpectrogramshow(y, sr):\n",
    "    X, _ = librosa.effects.trim(y)\n",
    "    XS = librosa.feature.melspectrogram(y=X, sr=sr)\n",
    "    Xdb = librosa.amplitude_to_db(XS, ref=np.max)\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar()   \n",
    "    \n",
    "show_in_plots(_melexpectrogramshow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a2d83",
   "metadata": {},
   "source": [
    "## Filtering Mel Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f14308",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "threshold = -60\n",
    "\n",
    "def _filtmelexpectrogramshow(y, sr):\n",
    "    X, _ = librosa.effects.trim(y)\n",
    "    XS = librosa.feature.melspectrogram(y=X, sr=sr)\n",
    "    Xdb = librosa.amplitude_to_db(XS, ref=np.max)\n",
    "    Xdb[Xdb < threshold] = threshold\n",
    "    librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar()   \n",
    "    \n",
    "show_in_plots(_filtmelexpectrogramshow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cf0453",
   "metadata": {},
   "source": [
    "## Mel spectrograms parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49471d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr, _ = all_waves['storm'][2]\n",
    "print(y.shape, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ba6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default parameters\n",
    "XS = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128, fmin=0.0, fmax=None)\n",
    "print(XS.shape)\n",
    "Xdb = librosa.amplitude_to_db(XS, ref=np.max)\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='mel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b45bd0b",
   "metadata": {},
   "source": [
    "The resultant array shape is (128, 431).\n",
    "- 128 is the number of mel bands\n",
    "- 431 is the number of time slots calculated. 430 aprox 220500/512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e49304",
   "metadata": {},
   "outputs": [],
   "source": [
    "220500/512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7472835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of mel bands. The more bands, the more filter details\n",
    "XS = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=40)\n",
    "print(XS.shape)\n",
    "Xdb = librosa.amplitude_to_db(XS, ref=np.max)\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='mel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2fb500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase hop_lengths\n",
    "XS = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=4096, n_mels=128, fmin=0.0, fmax=None)\n",
    "print(XS.shape)\n",
    "Xdb = librosa.amplitude_to_db(XS, ref=np.max)\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='mel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7b8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decrease hop_lengths\n",
    "XS = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=128, n_mels=128, fmin=0.0, fmax=None)\n",
    "print(XS.shape)\n",
    "Xdb = librosa.amplitude_to_db(XS, ref=np.max)\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='mel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353154ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing frequencies\n",
    "fmin = 2000\n",
    "fmax = 4000\n",
    "XS = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128, fmin=fmin, fmax=fmax)\n",
    "print(XS.shape)\n",
    "Xdb = librosa.amplitude_to_db(XS, ref=np.max)\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', hop_length=512, y_axis='mel', fmin=fmin, fmax=fmax)\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea8e83",
   "metadata": {},
   "source": [
    "## Animal sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d61c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls data/sounds/animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c763f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = 'data/sounds/animals/Katze_miaut.mp3'\n",
    "audio_file = 'data/sounds/animals/Puma.mp3'\n",
    "audio_file = 'data/sounds/animals/Tiger.mp3'\n",
    "audio_file = 'data/sounds/animals/donkey.mp3'\n",
    "audio_file = 'data/sounds/animals/Elefant.mp3'\n",
    "Audio(audio_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a66cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(audio_file, duration=5)\n",
    "XS = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "Xdb = librosa.amplitude_to_db(XS, ref=np.max)\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='mel')\n",
    "plt.colorbar() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b6156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_teach",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
